#!/usr/bin/env python3
"""
Script d'importation de POIs depuis Data.gouv.fr
Datasets publics fran√ßais : monuments historiques, mus√©es, √©quipements culturels
"""

import requests
import json
import time
import argparse
from typing import List, Dict, Optional
import csv
from io import StringIO

# URLs des datasets Data.gouv.fr
DATASETS = {
    'monuments': {
        'url': 'https://data.culture.gouv.fr/api/explore/v2.1/catalog/datasets/liste-des-immeubles-proteges-au-titre-des-monuments-historiques/exports/json',
        'category': 'histoire',
        'name_field': 'tico',
        'description_field': 'ppro',
        'lat_field': 'latitude',
        'lng_field': 'longitude',
        'city_field': 'commune'
    },
    'musees': {
        'url': 'https://data.culture.gouv.fr/api/explore/v2.1/catalog/datasets/liste-et-localisation-des-musees-de-france/exports/json',
        'category': 'culture',
        'name_field': 'nom_officiel',
        'description_field': 'adresse',
        'lat_field': 'latitude',
        'lng_field': 'longitude',
        'city_field': 'commune'
    },
    'equipements': {
        'url': 'https://www.data.gouv.fr/fr/datasets/r/0d8f0f0e-4d5f-4f7e-8c1b-5f3f9e4e3f5e',
        'category': 'activites',
        'name_field': 'nom',
        'description_field': 'type',
        'lat_field': 'latitude',
        'lng_field': 'longitude',
        'city_field': 'commune'
    }
}

def fetch_dataset(dataset_type: str, department: Optional[str] = None) -> List[Dict]:
    """
    R√©cup√®re un dataset depuis Data.gouv.fr
    
    Args:
        dataset_type: 'monuments', 'musees' ou 'equipements'
        department: Code d√©partement (ex: '75' pour Paris) - optionnel
    
    Returns:
        Liste de POIs
    """
    if dataset_type not in DATASETS:
        print(f"‚ùå Type de dataset inconnu: {dataset_type}")
        return []
    
    config = DATASETS[dataset_type]
    url = config['url']
    
    print(f"üì• T√©l√©chargement du dataset '{dataset_type}'...")
    print(f"   URL: {url}")
    
    try:
        # Param√®tres pour filtrer par d√©partement si sp√©cifi√©
        params = {}
        if department:
            params['refine.departement'] = department
        
        response = requests.get(url, params=params, timeout=60)
        response.raise_for_status()
        
        # D√©tecter le format de r√©ponse
        content_type = response.headers.get('Content-Type', '')
        
        if 'application/json' in content_type:
            data = response.json()
            
            # G√©rer diff√©rents formats de r√©ponse
            if isinstance(data, list):
                results = data
            elif isinstance(data, dict):
                # Format OpenDataSoft
                results = data.get('records', [])
                if results and 'fields' in results[0]:
                    results = [r['fields'] for r in results]
                # Format alternatif
                elif 'results' in data:
                    results = data['results']
                else:
                    results = [data]
            else:
                results = []
        
        elif 'text/csv' in content_type:
            # Parser le CSV
            csv_data = response.text
            csv_file = StringIO(csv_data)
            reader = csv.DictReader(csv_file)
            results = list(reader)
        
        else:
            print(f"‚ö†Ô∏è  Format inconnu: {content_type}")
            results = []
        
        print(f"   ‚úÖ {len(results)} entr√©es t√©l√©charg√©es")
        return results
    
    except Exception as e:
        print(f"   ‚ùå Erreur: {e}")
        return []

def filter_by_department(data: List[Dict], department: str, city_field: str) -> List[Dict]:
    """
    Filtre les donn√©es par d√©partement
    """
    if not department:
        return data
    
    filtered = []
    for item in data:
        # Essayer diff√©rents champs pour le d√©partement
        dept_code = item.get('departement', item.get('dep', item.get('code_departement', '')))
        
        # Normaliser le code d√©partement
        if isinstance(dept_code, str):
            dept_code = dept_code.zfill(2)  # '5' -> '05'
        
        if str(dept_code) == str(department).zfill(2):
            filtered.append(item)
    
    print(f"   üìç {len(filtered)} entr√©es pour le d√©partement {department}")
    return filtered

def convert_to_firestore_format(data: List[Dict], dataset_type: str) -> List[Dict]:
    """
    Convertit les donn√©es Data.gouv.fr au format Firestore
    """
    config = DATASETS[dataset_type]
    firestore_pois = []
    
    for idx, item in enumerate(data):
        try:
            # Extraire les champs selon la configuration
            name = item.get(config['name_field'], '')
            if not name or name == 'None':
                name = item.get('nom', item.get('titre', 'Sans nom'))
            
            # Position
            lat = item.get(config['lat_field'])
            lng = item.get(config['lng_field'])
            
            # G√©rer les coordonn√©es au format texte
            if isinstance(lat, str):
                lat = float(lat.replace(',', '.'))
            if isinstance(lng, str):
                lng = float(lng.replace(',', '.'))
            
            if not lat or not lng:
                continue
            
            # V√©rifier les coordonn√©es valides (France m√©tropolitaine)
            if not (41 <= lat <= 51 and -5 <= lng <= 10):
                continue
            
            # Description
            description = item.get(config['description_field'], '')
            if not description or description == 'None':
                description = item.get('adresse', item.get('adresse_complete', ''))
            
            # Ville
            city = item.get(config['city_field'], item.get('ville', 'Non sp√©cifi√©e'))
            
            # Images (souvent absentes dans data.gouv.fr)
            images = []
            image_url = item.get('image', item.get('illustration', ''))
            if image_url and image_url != 'None':
                images.append(image_url)
            
            # Construction du POI
            poi = {
                'name': str(name).strip(),
                'description': str(description).strip(),
                'location': {
                    '_latitude': float(lat),
                    '_longitude': float(lng)
                },
                'category': config['category'],
                'city': str(city).strip(),
                'images': images,
                'rating': 0.0,
                'website': item.get('url', item.get('site_internet', '')),
                'phone': item.get('telephone', ''),
                'isPublic': True,
                'isValidated': True,
                'source': f'datagouv_{dataset_type}',
                'createdAt': {'_seconds': int(time.time()), '_nanoseconds': 0}
            }
            
            # Champs sp√©cifiques aux monuments
            if dataset_type == 'monuments':
                poi['protection_type'] = item.get('protection', '')
                poi['historical_period'] = item.get('siecle', '')
            
            # Champs sp√©cifiques aux mus√©es
            if dataset_type == 'musees':
                poi['museum_type'] = item.get('type_musee', '')
                poi['collection'] = item.get('themes', '')
            
            firestore_pois.append(poi)
            
        except Exception as e:
            print(f"  ‚ö†Ô∏è  Erreur ligne {idx}: {e}")
            continue
    
    return firestore_pois

def main():
    parser = argparse.ArgumentParser(
        description='Importer des POIs depuis Data.gouv.fr (datasets publics)'
    )
    parser.add_argument('--dataset', required=True, 
                        choices=['monuments', 'musees', 'equipements', 'all'],
                        help='Type de dataset √† importer')
    parser.add_argument('--department', help='Code d√©partement (ex: 75 pour Paris)')
    parser.add_argument('--output', default='pois_datagouv_import.json',
                        help='Fichier de sortie JSON')
    
    args = parser.parse_args()
    
    print(f"üá´üá∑ Import Data.gouv.fr")
    print(f"üìÇ Dataset: {args.dataset}")
    if args.department:
        print(f"üìç D√©partement: {args.department}")
    print()
    
    all_pois = []
    
    # D√©terminer quels datasets importer
    datasets_to_import = DATASETS.keys() if args.dataset == 'all' else [args.dataset]
    
    for dataset_type in datasets_to_import:
        print(f"\nüìä Traitement: {dataset_type}")
        print("=" * 50)
        
        # T√©l√©charger les donn√©es
        data = fetch_dataset(dataset_type, args.department)
        
        if not data:
            print(f"‚ö†Ô∏è  Aucune donn√©e pour {dataset_type}")
            continue
        
        # Filtrer par d√©partement si n√©cessaire
        if args.department:
            config = DATASETS[dataset_type]
            data = filter_by_department(data, args.department, config['city_field'])
        
        # Convertir au format Firestore
        print(f"üîÑ Conversion au format Firestore...")
        pois = convert_to_firestore_format(data, dataset_type)
        print(f"   ‚úÖ {len(pois)} POIs convertis")
        
        all_pois.extend(pois)
    
    # Sauvegarde
    print(f"\nüíæ Sauvegarde de {len(all_pois)} POIs dans {args.output}...")
    with open(args.output, 'w', encoding='utf-8') as f:
        json.dump(all_pois, f, ensure_ascii=False, indent=2)
    
    print(f"\n‚úÖ Termin√© ! {len(all_pois)} POIs export√©s")
    print(f"üìÑ Fichier: {args.output}")
    print(f"üí∞ Co√ªt: GRATUIT (donn√©es publiques)")
    print("\nüî• Import dans Firestore:")
    print(f"   firebase firestore:import {args.output} --project allspots")
    
    # Statistiques par cat√©gorie
    print("\nüìä R√©partition par cat√©gorie:")
    categories = {}
    for poi in all_pois:
        cat = poi.get('category', 'unknown')
        categories[cat] = categories.get(cat, 0) + 1
    
    for cat, count in sorted(categories.items()):
        print(f"   {cat}: {count} POIs")

if __name__ == '__main__':
    main()
